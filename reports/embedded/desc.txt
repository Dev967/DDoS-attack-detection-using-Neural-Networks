Embedded Approach,
We now utilize SRC, DST ip addresses and ports by embedding
#IP
172.168.1.1 -> Splitting -> [172, 168, 1, 1]
    172 -> Embedding -> [0.13]
    168 -> Embedding -> [0.19]
    1   -> Embedding -> [0.98]
    1   -> Embedding -> [0.39]
#Port
3000 -> Embedding -> [0.34, 0.23, 0.89, 0.123]

### RNN ###
Layers: 1
Hidden Size: 128
Input size: 33 ( 8 for SRC and DST ip + 8 for SRC and DST port)
Features: ['DIRECTION', 'IP_TOS', 'DF', 'MF', 'IP_TTL', 'TCP_SPORT', 'TCP_DPORT',
       'TCP_RESERVED', 'FPA', 'FA', 'A', 'S', 'SA', 'PA', 'R', 'RA',
       'TCP_WINDOW', 'TCP_MSS', 'TCP_WSCALE', 'TYPE', 'SRC_IP_1', 'SRC_IP_2',
       'SRC_IP_3', 'SRC_IP_4', 'DST_IP_1', 'DST_IP_2', 'DST_IP_3', 'DST_IP_4']

### LINEAR ###
128 -> 50
ReLU
50 -> 2

### FINAL ###
Softmax

### PRE-TRAIN ###
-> SGD, CrosseEntropy, 0.1
LR suggestion: steepest gradient
Suggested LR: 1.28E-01
Epoch: 30
SGD lr = 0.1
    -- ONE CYCLE --
    |   max_lr  |   avg_loss    |   summary              |
    |-----------|---------------|------------------------|
    |  1.28E-01 |   0.7365      | no movements           |
    |-----------|---------------|------------------------|
    | 0.001    |   0.490        | slow movements         |
    |-----------|---------------|------------------------|
    | 0.0001    |   0.522       | slow          movements|
    |-----------|---------------|------------------------|
    |2e-3(0.002)|   0.521       |                        |
    |-----------|---------------|------------------------|

    -- CYCLIC --
    |   base_lr     |   max_lr      |   avg_loss    |   summary         |
    |---------------|---------------|---------------|-------------------|
    |   0.01        |   0.09        |   0.797       |                   |
    |---------------|---------------|---------------|-------------------|
    |   0.01        |   1.28E-1     |   0.738       |                   |
    |---------------|---------------|---------------|-------------------|
    |   0.0001      | 0.0009        |   0.521       |                   |
    |---------------|---------------|---------------|-------------------|
    |   0.001       |   0.009       |   0.540       |                   |
    |---------------|---------------|---------------|-------------------|
    |   0.0002      |   0.009       |   0.485       |                   |
    |---------------|---------------|---------------|-------------------|



-> Adam, CrossEntropy, 0.1
LR suggestion: steepest gradient
Suggested LR: 1.28E-01
epoch = 30
lr = NULL

  -- ONE CYCLE --
    |   max_lr  |   avg_loss    |   summary              |
    |-----------|---------------|------------------------|
    |  1.28E-01 |   0.73895     | no movements           |
    |-----------|---------------|------------------------|
    | 0.001     |   0.471       |dropped to 34 in between|
    |-----------|---------------|------------------------|
    |2e-3(0.002)|   0.754       |                        |
    |-----------|---------------|------------------------|
    | 0.0001    |   0.356       |                        |
    |-----------|---------------|------------------------|

  -- CYCLIC -- (ADAM does not support Momentum)
    |   base_lr     |   max_lr      |   avg_loss    |   summary         |
    |---------------|---------------|---------------|-------------------|
    |   0.01        |   0.09        |   0.73        | no change         |
    |---------------|---------------|---------------|-------------------|
    |   0.01        |   1.28E-1     |   0.73        | Loss dont change  |
    |---------------|---------------|---------------|-------------------|
    |   0.0001      | 0.0009        |   0.489       | lots of up downs  |
    |---------------|---------------|---------------|-------------------|
    |   0.001       |   0.009       |   0.86       |   went too high    |
    |---------------|---------------|---------------|-------------------|
    |   0.002       |   0.009       |   0.85        |                   |
    |---------------|---------------|---------------|-------------------|

-> AdamW, CrossEntropy, 0.1
LR suggestion: steepest gradient
Suggested LR: 1.28E-1
epoch = 30
lr = NULL
 -- ONE CYCLE --
    |   max_lr  |   avg_loss    |   summary              |
    |-----------|---------------|------------------------|
    |  1.28E-1  |   0.76        | no movements           |
    |-----------|---------------|------------------------|
    |  0.1      |   0.67        |                        |
    |-----------|---------------|------------------------|
    |  0.01     |   0.76        |                        |
    |-----------|---------------|------------------------|
    | 0.001     |   0.58        | lots of up and downs   |
    |-----------|---------------|------------------------|
    | 0.0001    |   0.35        | almost around 31-32    |
    |-----------|---------------|------------------------|
    |2e-3(0.002)|   0.75        | almost stuck at 0.85   |
    |-----------|---------------|------------------------|

    ADAMW also does not support (cyclic Momentum) results are gonna be almost same as ADAM

### TRAIN ###
Optimizer: AdamW(lr=0.0001)
Loss: CrossEntropyLoss()
Epoch: 30
Accuracy: 9656/10000  [96.55999755859375]

### VALIDATION ###
--- Session - 3 (60480) ---
0 = 50663
1 = 9880
NOTE: Session - 3 is completely unseen data not used in either training or testing, with completely different Benign, Target and Attack machine IP's

                 PRED 0    PRED 1
ACTUAL 0          47164      3468
ACTUAL 1          0          9848

 Accuracy: 57012/60480  [94.265869140625]

--- Session - 2 (10368) ---

                 PRED 0    PRED 1
ACTUAL 0          9621       747
ACTUAL 1          0          0

Accuracy: 9621/10368  [92.7951431274414]


### SUMMARY ###
Accuracy might be dropped from previous approach but results are considerably better
for inputs with all zeros, model predicts 5-10 1's when there should no 1's present in a 64 batched input
but on later inputs(after 100 batches) with more 1's and 0's in input model is able to predict perfectly

			  PRED 0 	 PRED 1
ACTUAL 0 	  6401  	  328
ACTUAL 1 	  0  	     3255


Examples:

-- Batch 72 --
64/64 correct, 100.0% [0: 9/9 1: 55/55]
ACTUAL:
 tensor([1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1])
PREDICTED:
 tensor([1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1])

-- Batch 75 --
64/64 correct, 100.0% [0: 19/19 1: 45/45]
ACTUAL:
 tensor([1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1,
        0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0,
        1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1])
PREDICTED:
 tensor([1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1,
        0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0,
        1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1])

-- Batch 104 --
64/64 correct, 100.0% [0: 32/32 1: 32/32]
ACTUAL:
 tensor([0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,
        0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,
        0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1])
PREDICTED:
 tensor([0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,
        0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,
        0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1])

