Classic Approach,

### RNN ###
Layers: 1
Hidden Size: 128
Input size: 17
Features: ['DIRECTION', 'IP_TOS', 'DF', 'MF', 'IP_TTL', 'TCP_SPORT', 'TCP_DPORT',
       'TCP_RESERVED', 'FPA', 'FA', 'A', 'S', 'SA', 'PA', 'R', 'RA',
       'TCP_WINDOW', 'TCP_MSS', 'TCP_WSCALE', 'TYPE']

### LINEAR ###
128 -> 50
ReLU
50 -> 2

### FINAL ###
Softmax

### PRE-TRAIN ###
-> SGD, CrosseEntropy, 0.1
LR suggestion: steepest gradient
Suggested LR: 3.73E+00
Epoch: 30
SGD lr = 0.1
    -- ONE CYCLE --
    |   max_lr  |   avg_loss    |   summary              |
    |-----------|---------------|------------------------|
    |  3.73E+00 |   0.73895     | no movements           |
    |-----------|---------------|------------------------|
    | 0.0001    |   0.5591      | slow, up-down movements|
    |-----------|---------------|------------------------|
    |2e-3(0.002)|   0.5193      |                        |
    |-----------|---------------|------------------------|

    -- CYCLIC --
    |   base_lr     |   max_lr      |   avg_loss    |   summary         |
    |---------------|---------------|---------------|-------------------|
    |   0.01        |   0.09        |   0.62        |                   |
    |---------------|---------------|---------------|-------------------|
    |   0.01        |   3.73E+00    |   0.73        | Loss dont change  |
    |---------------|---------------|---------------|-------------------|
    |   0.0001      | 0.0009        |   0.52        | almost static@0.52|
    |---------------|---------------|---------------|-------------------|
    |   0.001       |   0.009       |   0.544       | beginning 0.49    |
    |---------------|---------------|---------------|-------------------|
    |   0.002       |   0.009       |   0.55        |   went to high    |
    |---------------|---------------|---------------|-------------------|



-> Adam, CrossEntropy, 0.1
LR suggestion: steepest gradient
Suggested LR: 2.87E+00
epoch = 30
lr = NULL

  -- ONE CYCLE --
    |   max_lr  |   avg_loss    |   summary              |
    |-----------|---------------|------------------------|
    |  2.87E+00 |   0.73895     | no movements           |
    |-----------|---------------|------------------------|
    | 0.001     |   0.5891      | good start             |
    |-----------|---------------|------------------------|
    |2e-3(0.002)|   0.5193      |                        |
    |-----------|---------------|------------------------|
    | 0.0001    |   0.3698      |                        |
    |-----------|---------------|------------------------|

  -- CYCLIC -- (ADAM does not support Momentum)
    |   base_lr     |   max_lr      |   avg_loss    |   summary         |
    |---------------|---------------|---------------|-------------------|
    |   0.01        |   0.09        |   0.73        | no change         |
    |---------------|---------------|---------------|-------------------|
    |   0.01        |   2.87E+00    |   0.73        | Loss dont change  |
    |---------------|---------------|---------------|-------------------|
    |   0.0001      | 0.0009        |   0.72        | lots of up downs  |
    |---------------|---------------|---------------|-------------------|
    |   0.001       |   0.009       |   0.86        |   went too high    |
    |---------------|---------------|---------------|-------------------|
    |   0.002       |   0.009       |   0.78        |                   |
    |---------------|---------------|---------------|-------------------|

-> AdamW, CrossEntropy, 0.1
LR suggestion: steepest gradient
Suggested LR: 2.32E+00
epoch = 30
lr = NULL
 -- ONE CYCLE --
    |   max_lr  |   avg_loss    |   summary              |
    |-----------|---------------|------------------------|
    |  2.32E+00 |   0.60        | no movements           |
    |-----------|---------------|------------------------|
    | 0.001     |   0.58        | lots of up and downs   |
    |-----------|---------------|------------------------|
    |2e-3(0.002)|   0.75        | almost stuck at 0.85   |
    |-----------|---------------|------------------------|
    | 0.0001    |   0.35        | almost around 31-32    |
    |-----------|---------------|------------------------|

    ADAMW also does not support (cyclic Momentum) results are gonna be almost same as ADAM

### TRAIN ###
Optimizer: AdamW(lr=0.0001)
Loss: CrossEntropyLoss()
Epoch: 30
-- BEFORE (Naive Approach without any consideration) --
Accuracy: 7817/10000  [78.16999816894531]
-- AFTER --
Accuracy: 9830/10000  [98.29999542236328]

### SUMMARY ###
model is capable of learning. But is learning very slowly. Learning almost stops after loss reaches 0.35
Model treats whole Dataset as one big sequence, hidden state is same for entire dataset.
Model does not make use of SRC and DST IP addresses, Ports